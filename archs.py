import torch
import torch.nn as nn
import torch.nn.functional as F


# The sender receives targets first, then distractors and is thus implicitly informed
# about which are the targets (used in Lazaridou et al. 2017).

class Sender(nn.Module):
    """
    Sender gets as input targets and distractors in an ordered fashion (targets first).
    It embeds both targets and distractors and returns a joint embedding.
    """

    def __init__(self, n_hidden, n_features, n_targets, context_unaware=False):
        super(Sender, self).__init__()
        # embedding layers:
        self.fc1 = nn.Linear(n_features * n_targets, n_hidden)
        self.fc2 = nn.Linear(n_features * n_targets, n_hidden)
        self.fc3 = nn.Linear(2 * n_hidden, n_hidden)
        self.context_unaware = context_unaware

    def forward(self, x, aux_input=None):
        batch_size = x.shape[0]
        n_obj = x.shape[1]
        n_features = x.shape[2]
        n_targets = int(n_obj / 2)

        # embed target objects:
        targets = x[:, :n_targets]
        targets_flat = targets.reshape(batch_size, n_targets * n_features)
        target_feature_embedding = F.relu(self.fc1(targets_flat))

        # context unaware speakers only process the targets
        if self.context_unaware:
            return target_feature_embedding

        # context aware speakers process both targets and distractors
        else:
            # embed distractor objects:
            distractors = x[:, n_targets:]
            distractors_flat = distractors.reshape(batch_size, n_targets * n_features)
            distractor_feature_embedding = F.relu(self.fc2(distractors_flat))

            # create joint embedding
            joint_embedding = self.fc3(
                torch.cat([target_feature_embedding, distractor_feature_embedding], dim=1)).tanh()
            return joint_embedding


class Receiver(nn.Module):
    def __init__(self, n_features, n_hidden):
        """
        Receives as input the vector generated by the message-decoding RNN in the wrapper (x)
        and game-specific input (input, i.e. matrix containing all input attribute-value vectors).
        The module maps these vectors to the same dimensionality as the RNN output vector, 
        and computes a dot product between the latter and each of the (transformed) input vectors.
        The output dot product list is interpreted as a non-normalized probability distribution 
        over possible positions of the target.
        """
        super(Receiver, self).__init__()
        # embedding layer
        self.fc1 = nn.Linear(n_features, n_hidden)

    def forward(self, x, input, _aux_input=None):
        # from EGG: the rationale for the non-linearity here is that the RNN output will also be the 
        # outcome of a non-linearity
        embedded_input = self.fc1(input).tanh()
        dots = torch.matmul(embedded_input, torch.unsqueeze(x, dim=-1))
        return dots.squeeze()
